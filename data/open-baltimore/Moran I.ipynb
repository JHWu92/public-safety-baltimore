{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import pysal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crs_prepossess(gpdf, bfr_crs, init_crs=4326):\n",
    "    \"\"\"\n",
    "    create a shallow copy of gpdf; check the init crs of gpdf, if None, assign init_crs; change crs of copy to bfr_crs\n",
    "    :param gpdf: geopandas.GeoDataFrame\n",
    "    :param init_crs: init_crs epsg code\n",
    "    :param bfr_crs: target crs epsg code used for buffering\n",
    "    :return: a shallow copy of gpdf in bfr_crs\n",
    "    \"\"\"\n",
    "    gpdf_crs = gpdf.copy()\n",
    "    if gpdf_crs.crs == None:\n",
    "        gpdf_crs.crs = {'init': u'epsg:{}'.format(init_crs)}\n",
    "    return gpdf_crs.to_crs(epsg=bfr_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PySAL compute euclidean distance between centroid of shapes\n",
    "# Therefore the segments should be represented in suitable CRS instead of lat/lon (4326)\n",
    "\n",
    "seg_in_lat_lon = gpd.read_file('some/file/with/geometry/column')\n",
    "seg_in_ph_crs = crs_prepossess(seg_in_lat_lon, crs_for_ph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute weights matrix between segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# There are different kinds of distance weights\n",
    "# e.g. K nearest neighbours\n",
    "ks = [1,2,3,4,5,6,7,8, 9, 10]\n",
    "ws_knn = {k: pysal.weights.KNN.from_dataframe(seg_in_ph_crs[['geometry']], k=k) for k in ks}\n",
    "\n",
    "# e.g. distanct band\n",
    "# There are 2 kinds of distant band weight, binary or non-binary. I don't know the exact difference between them. \n",
    "# with correct CRS, the unit of the following dbs is meter\n",
    "dbs = [10, 50, 100, 150, 200, 300, 400]\n",
    "ws_db_notbinary = {db: pysal.weights.DistanceBand.from_dataframe(seg_in_ph_crs[['geometry']], threshold=db, binary=False, silent=True) for db in dbs}\n",
    "ws_db_binary = {db: pysal.weights.DistanceBand.from_dataframe(seg_in_ph_crs[['geometry']], threshold=db, binary=True, silent=True) for db in dbs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for KNN, every shape has k neighbors\n",
    "# but for distance band, there are some islands which has no neighbors\n",
    "# I choose 150 meter binary distance band weight in the cycling safety project considering the percentage of islands.\n",
    "islands = [ws_db_binary[db].islands.__len__() for db in dbs]\n",
    "pd.DataFrame(list(zip(dbs, islands)), columns=['band', 'num_islands']).set_index('band').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute moran i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_moran_i(ws, param_list, x, pname):\n",
    "    res = []\n",
    "\n",
    "    for i, cname in enumerate(x):\n",
    "        if i % 40 == 0:\n",
    "            print('i=', i, cname)\n",
    "            \n",
    "        data = x[cname]\n",
    "        for p in param_list:\n",
    "            w = ws[p]\n",
    "            mi = pysal.Moran(data, w, two_tailed=True, permutations=999)\n",
    "            res.append({\n",
    "                'column':cname, \n",
    "                pname:p,\n",
    "                'I': mi.I, \n",
    "                'EI': mi.EI, \n",
    "                'p_norm': mi.p_norm * 2,\n",
    "                'p_rand': mi.p_rand * 2,\n",
    "                'z_norm': mi.z_norm,\n",
    "                'z_rand': mi.z_rand,\n",
    "            })\n",
    "    print('done computing', pname)\n",
    "    df = pd.DataFrame(res)\n",
    "    return df[['column', pname, 'I', 'EI', 'p_norm', 'p_rand', 'z_norm', 'z_rand', 'p_sim', 'p_z_sim']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make sure the index of X corresponds with the segment, starting from 0\n",
    "\n",
    "X = pd.read_csv('the/feature/dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the function loop over each column of the features X. \n",
    "# It took quite a while for me to compute 200 features, maybe 1 hour or 2\n",
    "# PySAL provides a function to compute moran I directly from a dataframe\n",
    "# I don't know if that function would be faster\n",
    "\n",
    "df_db_binary = compute_moran_i(ws_db_binary, dbs, x, 'db_b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# p_norm and z_norm are the p and z value under normal distribution assumption\n",
    "# p_rand and z_rand are the p and z value under random assumption\n",
    "# I don't know what is the exact difference between them, but I chose p_rand<0.05 to identify significant features\n",
    "\n",
    "def len_sig_features(df):\n",
    "    return((df.p_rand<0.05).sum())\n",
    "\n",
    "print(X.shape)\n",
    "df_db_binary_total.groupby('db_b').apply(len_sig_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# average of neighbors' feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "band = 150\n",
    "db_150 = df_db_binary.db_b==band\n",
    "sig_rand = df_db_binary.p_rand<0.05\n",
    "sig_cols = df_db_binary[db_150 & sig_rand].column.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_db_binary[db_150 & sig_rand].I.plot(kind='hist',title='Moran I distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the neighbors of the first segment\n",
    "ws_db_binary[150].neighbors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this also takes quite a while to compute\n",
    "# maybe you can find a better way\n",
    "\n",
    "res = {}\n",
    "for col in sig_cols:\n",
    "    column = x[col]\n",
    "    new_col = {}\n",
    "    for i, neighbor in ws_db_binary[band].neighbors.items():\n",
    "        new_col[i] = column[neighbor].mean()\n",
    "        res[col+'_neighbor'] = new_col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_neighbor = pd.DataFrame(res)\n",
    "\n",
    "# you may want to store the result first\n",
    "x_neighbor.to_csv('some/csv/file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# positive Moran I means spatially clustered effect, negative means spatially dispersed effect\n",
    "# the larger the abs(I) is, the stronger the effect is\n",
    "# You may wanna keep features with strong effect only\n",
    "\n",
    "for i_thres in [0, 0.1, 0.3, 0.5, 0.7, 0.8, 0.9]:\n",
    "    pass_i_thres = df_db_binary.I.abs()>=i_thres\n",
    "    keep_cols = df_db_binary[db_150 & sig_rand & pass_i_thres].column\n",
    "    keep_cols = (keep_cols+'_neighbor').tolist()\n",
    "#     x_neighbor[keep_cols].to_csv('spatial-corr/x-neighbor-db-150-binary-i-%0.1f.csv' % i_thres)\n",
    "    print(i_thres, len(keep_cols))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
