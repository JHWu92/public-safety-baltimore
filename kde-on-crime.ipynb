{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "from shapely.geometry import Point, Polygon, box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_grids(shape, grid_size=200, crs=None):\n",
    "    from shapely.geometry import Polygon, LineString\n",
    "    do_intersect = False\n",
    "    \n",
    "    if isinstance(shape, tuple):\n",
    "        if len(shape)==4:\n",
    "            lon_min, lat_min, lon_max, lat_max = shape\n",
    "        else:\n",
    "            print('shape is a tuple, but its len != 4')\n",
    "    elif isinstance(shape, LineString):\n",
    "        if shape.is_closed:\n",
    "            lon_min, lat_min, lon_max, lat_max = shape.bounds\n",
    "            shape = Polygon(shape)\n",
    "            do_intersect = True\n",
    "        else:\n",
    "            print('shape is LineString but not closed, which is not supported here')\n",
    "    elif isinstance(shape, Polygon):\n",
    "        lon_min, lat_min, lon_max, lat_max = shape.bounds\n",
    "        do_intersect = True\n",
    "    else:\n",
    "        print('shape is not bbox tuple, closed LineString or Polygon')\n",
    "        \n",
    "    grid_lon, grid_lat = np.mgrid[lon_min:lon_max:grid_size, lat_min:lat_max:grid_size]\n",
    "    grids_poly = []\n",
    "    for j in range(grid_lat.shape[1]-1):\n",
    "        for i in range(grid_lon.shape[0]-1):\n",
    "            g = box(grid_lon[i,j], grid_lat[i,j], grid_lon[i+1,j+1], grid_lat[i+1,j+1])\n",
    "            if do_intersect and not g.intersects(shape):\n",
    "                continue\n",
    "            grids_poly.append(g)\n",
    "    \n",
    "    grids = gp.GeoDataFrame(grids_poly).rename(columns={0: 'geometry'})\n",
    "    grids['cxcy'] = grids.geometry.apply(lambda x: x.centroid.coords[0])\n",
    "    if crs is not None:\n",
    "        grids.crs = crs\n",
    "    return grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cityline = gp.read_file('data/open-baltimore/raw/Baltcity_20Line/baltcity_line.shp')\n",
    "cityline = cityline.to_crs(epsg=3559)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_size=200\n",
    "grids = get_grids(cityline.geometry[0], grid_size)\n",
    "print(grids.shape)\n",
    "grids.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grids.crs= cityline.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# crime data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_df = pd.read_csv('data/open-baltimore/raw/BPD_Part_1_Victim_Based_Crime_Data.csv')\n",
    "crimes_df['geometry'] = crimes_df.apply(lambda x: Point(x.Longitude, x.Latitude), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_4326 = gp.GeoDataFrame(crimes_df[~crimes_df.Longitude.isnull()][['geometry', 'CrimeDate', 'CrimeTime', 'CrimeCode', 'Weapon']])\n",
    "crimes_4326.crs = {'init': 'epsg:4326'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crimes = crimes_4326.to_crs(epsg=3559)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# crimes['lon'] = crimes.geometry.apply(lambda x: x.coords[0][0])\n",
    "# crimes['lat'] = crimes.geometry.apply(lambda x: x.coords[0][1])\n",
    "crimes['lonlat'] = crimes.geometry.apply(lambda x: x.coords[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crimes['CrimeDate'] = pd.to_datetime(crimes['CrimeDate'], format='%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crimes = crimes.reset_index().set_index('CrimeDate').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = crimes.index.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates_bw = dates[dates<'2014-01-01']\n",
    "dates_eval = dates[dates>='2014-01-01']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KernelDensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bandwidth_selection(data, pt_col='lonlat', bw_choice=None, cv=20):\n",
    "    pts = data[pt_col].tolist()\n",
    "    if bw_choice is None:\n",
    "        bw_choice = np.linspace(10, 1000, 30)\n",
    "    search = GridSearchCV(KernelDensity(), {'bandwidth': bw_choice}, cv=cv)\n",
    "    search.fit(pts)\n",
    "    print(search.best_params_)\n",
    "    return search.best_params_['bandwidth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_slice = crimes.loc[dates[0]: dates[365]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw = bandwidth_selection(crimes.loc[dates_bw[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rolling_window(data, pt_col='lonlat', time_window=60, verbose=True):\n",
    "    \"\"\"\n",
    "    data: pd.DataFrame, index is DatetimeIndex, sorted by index.\n",
    "    \"\"\"\n",
    "    dates = data.index.unique()\n",
    "    if len(dates)<=time_window:\n",
    "        raise ValueError('len of dates (%d) is less than time_window (%d)' % (len(dates), time_window))\n",
    "    num_experiment = len(dates)-time_window\n",
    "    if verbose:\n",
    "        print('total number of experiment:', num_experiment)\n",
    "    for i in range(num_experiment):\n",
    "        test_date = dates[i+time_window]\n",
    "        train_start_date = test_date - pd.Timedelta(days=time_window)\n",
    "        train_end_date = test_date - pd.Timedelta(days=1)\n",
    "        \n",
    "        train = data.loc[train_start_date:train_end_date]\n",
    "        test = data.loc[test_date]\n",
    "#         print(train_start_date, train_end_date, test_date, train.index.nunique())\n",
    "        yield train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kde_rolling(data, grids, bw, pt_col='lonlat', return_test_dates=True, verbose=True):\n",
    "    test_dates = []\n",
    "    for train, test in rolling_window(data, verbose=verbose):\n",
    "        test_date_str = test.index.unique()[0].strftime('%Y-%m-%d')\n",
    "        test_dates.append(test_date_str)\n",
    "        if verbose:\n",
    "            print(train.shape, test.shape, test.index.unique()[0].strftime('%Y-%m-%d'))\n",
    "        # kde\n",
    "        kde = KernelDensity(bandwidth=bw)\n",
    "        kde.fit(train[pt_col].tolist())\n",
    "        pdf = np.exp(kde.score_samples(grids['cxcy'].tolist()))\n",
    "        grids['density_'+test_date_str] = pdf\n",
    "        # test in grids\n",
    "        test_in_grids = gp.sjoin(test, grids)\n",
    "        grids =grids.join(test_in_grids.groupby('index_right').agg({'index':'count'}), how='left')\\\n",
    "                        .rename(columns={'index':'num_crimes_'+test_date_str}).fillna(0)\n",
    "    if return_test_dates:\n",
    "        return grids, test_dates\n",
    "    return grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids_with_result, test_dates = kde_rolling(crimes.loc[dates[:70]], grids.copy(), bw, return_test_dates=True, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs = []\n",
    "for test_date_str in test_dates:\n",
    "    grids_with_result.sort_values('density_'+test_date_str, ascending=False, inplace=True)\n",
    "    hit_rate = grids_with_result['num_crimes_'+test_date_str].cumsum()/grids_with_result['num_crimes_'+test_date_str].sum()\n",
    "    auc = hit_rate.iloc[idx_for_auc]\n",
    "    auc.index = ['%d0%%' % (i+1) for i in range(10)]\n",
    "    aucs.append(auc)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merge_aucs2 = pd.concat(aucs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_aucs = pd.concat(aucs,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_aucs.mean(axis=1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_aucs.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
